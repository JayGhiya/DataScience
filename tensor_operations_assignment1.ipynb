{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayGhiya/DataScience/blob/master/tensor_operations_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQLUIIOBFjmS",
        "colab_type": "text"
      },
      "source": [
        "**PYTORCH101**  \n",
        "\n",
        "### *Tensors*\n",
        "\n",
        "An short introduction about PyTorch and about the chosen functions. \n",
        "- torch.as_tensor(data, dtype=None, device=None) → Tensor\n",
        "- function 2\n",
        "- function 3\n",
        "- function 4\n",
        "- function 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTS3aFaQFjmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVcW3InnFjmX",
        "colab_type": "text"
      },
      "source": [
        "## Function 1 - torch.as_tensor(data, dtype=None, device=None) → Tensor\n",
        "\n",
        "Converts the data into a torch tensor. If the data is an ndarray of the corresponding dtype and the device is CPU, no copy will be performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIdUncaMFjmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2e8f2126-e28e-433f-a720-64cf5dbf33df"
      },
      "source": [
        "# Example 1 - working (change this)\n",
        "np_array = numpy.array([[4.,5.,6.],[7.,8.,9.],[10.,11.,12.]])\n",
        "t_1 = torch.as_tensor(data = np_array , device=torch.device('cpu')) \n",
        "t_1.size(),t_1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), tensor([[ 4.,  5.,  6.],\n",
              "         [ 7.,  8.,  9.],\n",
              "         [10., 11., 12.]], dtype=torch.float64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjJCOp-qVLUN",
        "colab_type": "text"
      },
      "source": [
        "Now let us try to modify the tensor using indexing of numpy arrays and see the change in original numpy array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd6i0DWiFjmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d92e852a-0fef-49cb-9161-9924e47e34c6"
      },
      "source": [
        "# Example 2 - working\n",
        "t_1[0][0] = 10\n",
        "np_array"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10.,  5.,  6.],\n",
              "       [ 7.,  8.,  9.],\n",
              "       [10., 11., 12.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ktS5LzbFjme",
        "colab_type": "text"
      },
      "source": [
        "Torch as tensor api supports building tensor from tuple,list,ndarray and scalar but not set. As set does not support duplicate values which may be part of tensor and needed for further computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz9R04r2Fjmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "fd38815d-f559-44e6-e92c-d1cc5a18ee8a"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.as_tensor({1,23,3,4})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-25996525edd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of set"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEZUmgVpFjmh",
        "colab_type": "text"
      },
      "source": [
        "To summarize we have used torch.as_tensor to generate a tensor out of numpy array without copying the data of numpy array by saving space. Also we saw how modifying tensor automatically modifies the numpy array which is a handy thing as we can do direct visualizations on numpy array using matplotlib lib after using operations on tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFwnxXnoFjmi",
        "colab_type": "text"
      },
      "source": [
        "torch.tensor() always copies data. If you have a Tensor data and just want to change its requires_grad flag, use requires_grad_() or detach() to avoid a copy. If you have a numpy array and want to avoid a copy, use torch.as_tensor().\n",
        "\n",
        "```\n",
        "# reference:  https://pytorch.org/docs/stable/torch.html#torch.as_tensor\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9igrVv4qFjmi",
        "colab_type": "text"
      },
      "source": [
        "## Function 2 - torch.stack(tensors, dim=0, out=None) → Tensor\n",
        "It adds new tensors along a new dimension. Now let us try to add a tensor using stack to existing tensor t_1. We will use torch.from_numpy() to generate a new tensor and then use torch.stack() to perform the stack operation along dimension 0.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dxlBUHfFjmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "d3166516-e38c-422c-ec70-8ecfdfe42b3a"
      },
      "source": [
        "# Example 1 - working\n",
        "t_2 = torch.from_numpy(numpy.array([[1.,8.,10.],[12.,14.,16.],[19.,20.,25.]]))\n",
        "t_2\n",
        "t_3 = torch.stack([t_1,t_2])\n",
        "t_3,t_3.size()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[10.,  5.,  6.],\n",
              "          [ 7.,  8.,  9.],\n",
              "          [10., 11., 12.]],\n",
              " \n",
              "         [[ 1.,  8., 10.],\n",
              "          [12., 14., 16.],\n",
              "          [19., 20., 25.]]], dtype=torch.float64), torch.Size([2, 3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfYR1yEPFjmn",
        "colab_type": "text"
      },
      "source": [
        "The stack function can be used when we are training on a batch of say 2d images which will have 2 dimensions. So what batch operation will do is stack n number of images along 0 dimension for that batch and then iterate over that dimension to get list of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwHW_A23Fjmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "402827c1-481d-46f0-b8b5-ba8de13c60dd"
      },
      "source": [
        "# Example 2 - working\n",
        "for image in t_3:\n",
        "  #do training\n",
        "  print(image)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[10.,  5.,  6.],\n",
            "        [ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]], dtype=torch.float64)\n",
            "tensor([[ 1.,  8., 10.],\n",
            "        [12., 14., 16.],\n",
            "        [19., 20., 25.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v91hT98Fjmq",
        "colab_type": "text"
      },
      "source": [
        "As we are stacking tensors along dimension 0 it is important to understand that tensors that need to be stacked have to be of same operation. if they are not then error will be thrown stating dimensions are not of same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJUl4GUSFjmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "5642980d-676c-47e0-ee9e-553649ccc47a"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "t_4 = torch.from_numpy(numpy.array([[1.,8.,10.,11.],[12.,14.,16.,17.],[19.,20.,25.,26.]]))\n",
        "t_5 = torch.stack([t_1,t_4])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b690eace9753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 3] at entry 0 and [3, 4] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVEiIj7FFjmt",
        "colab_type": "text"
      },
      "source": [
        "Here we saw how stack operation of tensor can be used to load multiple examples of same tensor size across a new dimension which is zero by default.\n",
        "\n",
        "\n",
        "```\n",
        "# reference: https://pytorch.org/docs/master/generated/torch.stack.html\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQZaWKvDFjmt",
        "colab_type": "text"
      },
      "source": [
        "It can be used when we are training with multiple examples. For instance can be used to stack 2d images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iu8JTRrFjmu",
        "colab_type": "text"
      },
      "source": [
        "## Function 3 - ???\n",
        "\n",
        "Add some explanations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQrUnHe5Fjmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 1 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDDG1b2EFjmx",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDccJMO7Fjmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 2 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JYbX_iPFjm0",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boM7KmmLFjm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTkPWLDpFjm4",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJPv526jFjm5",
        "colab_type": "text"
      },
      "source": [
        "Closing comments about when to use this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Zmk6KtFjm5",
        "colab_type": "text"
      },
      "source": [
        "## Function 4 - ???\n",
        "\n",
        "Add some explanations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv9oBxnVFjm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 1 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urBwD2zkFjm8",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFZq5N4PFjm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 2 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJEya4fgFjm_",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iohisihFjm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA0E2ZTtFjnC",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3zkTG4bFjnC",
        "colab_type": "text"
      },
      "source": [
        "Closing comments about when to use this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYlIzU1oFjnD",
        "colab_type": "text"
      },
      "source": [
        "## Function 5 - ???\n",
        "\n",
        "Add some explanations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEgK28QTFjnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 1 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDeegUb0FjnG",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43wQ44-CFjnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 2 - working"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biOCukiAFjnK",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yunq-dFkFjnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAFuu-2JFjnN",
        "colab_type": "text"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LTnBHw-FjnN",
        "colab_type": "text"
      },
      "source": [
        "Closing comments about when to use this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXZ8NPWFjnO",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Summarize what was covered in this notebook, and where to go next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq_vauooFjnO",
        "colab_type": "text"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceG7MHfgFjnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2c5a745b-3f99-4bfd-8016-06e8d55ee53f"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████                            | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.3MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed5AxXUVFjnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jovian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbzC9UZzFjnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a002206-a469-42c1-8cb6-d35dfffe2a24"
      },
      "source": [
        "jovian.commit()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[jovian] Error: Failed to detect Jupyter notebook or Python script. Skipping..\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XrJa2sQFjnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}